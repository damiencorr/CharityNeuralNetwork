{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alphabet Soup Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import warnings\n",
    "import numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "\n",
    "#Supress distracting deprication warnings\n",
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and characterize the input data\n",
    "Identify the following in your dataset:\n",
    "\n",
    "- What variable(s) are considered the target for your model?\n",
    "- What variable(s) are considered to be the features for your model?\n",
    "- What variable(s) are neither and should be removed from the input data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>996009318</td>\n",
       "      <td>THE LIONS CLUB OF HONOLULU KAMEHAMEHA</td>\n",
       "      <td>T4</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>996010315</td>\n",
       "      <td>INTERNATIONAL ASSOCIATION OF LIONS CLUBS</td>\n",
       "      <td>T4</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>996012607</td>\n",
       "      <td>PTA HAWAII CONGRESS</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>996015768</td>\n",
       "      <td>AMERICAN FEDERATION OF GOVERNMENT EMPLOYEES LO...</td>\n",
       "      <td>T5</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>996086871</td>\n",
       "      <td>WATERHOUSE CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1M-5M</td>\n",
       "      <td>N</td>\n",
       "      <td>36500179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             EIN                                               NAME  \\\n",
       "0       10520599                       BLUE KNIGHTS MOTORCYCLE CLUB   \n",
       "1       10531628             AMERICAN CHESAPEAKE CLUB CHARITABLE TR   \n",
       "2       10547893                 ST CLOUD PROFESSIONAL FIREFIGHTERS   \n",
       "3       10553066                     SOUTHSIDE ATHLETIC ASSOCIATION   \n",
       "4       10556103           GENETIC RESEARCH INSTITUTE OF THE DESERT   \n",
       "...          ...                                                ...   \n",
       "34294  996009318              THE LIONS CLUB OF HONOLULU KAMEHAMEHA   \n",
       "34295  996010315           INTERNATIONAL ASSOCIATION OF LIONS CLUBS   \n",
       "34296  996012607                                PTA HAWAII CONGRESS   \n",
       "34297  996015768  AMERICAN FEDERATION OF GOVERNMENT EMPLOYEES LO...   \n",
       "34298  996086871                           WATERHOUSE CHARITABLE TR   \n",
       "\n",
       "      APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0                  T10       Independent          C1000    ProductDev   \n",
       "1                   T3       Independent          C2000  Preservation   \n",
       "2                   T5  CompanySponsored          C3000    ProductDev   \n",
       "3                   T3  CompanySponsored          C2000  Preservation   \n",
       "4                   T3       Independent          C1000     Heathcare   \n",
       "...                ...               ...            ...           ...   \n",
       "34294               T4       Independent          C1000    ProductDev   \n",
       "34295               T4  CompanySponsored          C3000    ProductDev   \n",
       "34296               T3  CompanySponsored          C2000  Preservation   \n",
       "34297               T5       Independent          C3000    ProductDev   \n",
       "34298               T3       Independent          C1000  Preservation   \n",
       "\n",
       "       ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS   ASK_AMT  \\\n",
       "0       Association       1              0                      N      5000   \n",
       "1      Co-operative       1         1-9999                      N    108590   \n",
       "2       Association       1              0                      N      5000   \n",
       "3             Trust       1    10000-24999                      N      6692   \n",
       "4             Trust       1  100000-499999                      N    142590   \n",
       "...             ...     ...            ...                    ...       ...   \n",
       "34294   Association       1              0                      N      5000   \n",
       "34295   Association       1              0                      N      5000   \n",
       "34296   Association       1              0                      N      5000   \n",
       "34297   Association       1              0                      N      5000   \n",
       "34298  Co-operative       1          1M-5M                      N  36500179   \n",
       "\n",
       "       IS_SUCCESSFUL  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                  0  \n",
       "3                  1  \n",
       "4                  1  \n",
       "...              ...  \n",
       "34294              0  \n",
       "34295              0  \n",
       "34296              0  \n",
       "34297              1  \n",
       "34298              0  \n",
       "\n",
       "[34299 rows x 12 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the data path and source file\n",
    "data = os.path.join(\"Resources\", \"charity_data.csv\")\n",
    "# Import the dataset into a dataframe\n",
    "rawdata_df = pd.read_csv(data)\n",
    "rawdata_df#.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset description provided as part of the Challenge resources\n",
    "    \n",
    "The dataset contains more than 34,000 organizations that have received various amounts of funding from Alphabet Soup over the years. \n",
    "\n",
    "Within this dataset are a number of columns that capture metadata about each organization such as the following:\n",
    "\n",
    "- EIN and NAME—Identification columns\n",
    "- APPLICATION_TYPE—Alphabet Soup application type\n",
    "- AFFILIATION—Affiliated sector of industry\n",
    "- CLASSIFICATION—Government organization classification\n",
    "- USE_CASE—Use case for funding\n",
    "- ORGANIZATION—Organization type\n",
    "- STATUS—Active status\n",
    "- INCOME_AMT—Income classification\n",
    "- SPECIAL_CONSIDERATIONS—Special consideration for application\n",
    "- ASK_AMT—Funding amount requested\n",
    "- IS_SUCCESSFUL—Was the money used effectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34299, 12)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the data\n",
    "rawdata_df.shape\n",
    "\n",
    "# There are 34k+ rows with 12 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EIN                        int64\n",
       "NAME                      object\n",
       "APPLICATION_TYPE          object\n",
       "AFFILIATION               object\n",
       "CLASSIFICATION            object\n",
       "USE_CASE                  object\n",
       "ORGANIZATION              object\n",
       "STATUS                     int64\n",
       "INCOME_AMT                object\n",
       "SPECIAL_CONSIDERATIONS    object\n",
       "ASK_AMT                    int64\n",
       "IS_SUCCESSFUL              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the types of the datasets' columns\n",
    "rawdata_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.429900e+04</td>\n",
       "      <td>34299.000000</td>\n",
       "      <td>3.429900e+04</td>\n",
       "      <td>34299.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.191852e+08</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>2.769199e+06</td>\n",
       "      <td>0.532406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.451472e+08</td>\n",
       "      <td>0.012073</td>\n",
       "      <td>8.713045e+07</td>\n",
       "      <td>0.498956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.052060e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.748482e+08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.656317e+08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.526117e+08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.742000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.960869e+08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.597806e+09</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                EIN        STATUS       ASK_AMT  IS_SUCCESSFUL\n",
       "count  3.429900e+04  34299.000000  3.429900e+04   34299.000000\n",
       "mean   5.191852e+08      0.999854  2.769199e+06       0.532406\n",
       "std    2.451472e+08      0.012073  8.713045e+07       0.498956\n",
       "min    1.052060e+07      0.000000  5.000000e+03       0.000000\n",
       "25%    2.748482e+08      1.000000  5.000000e+03       0.000000\n",
       "50%    4.656317e+08      1.000000  5.000000e+03       1.000000\n",
       "75%    7.526117e+08      1.000000  7.742000e+03       1.000000\n",
       "max    9.960869e+08      1.000000  8.597806e+09       1.000000"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdata_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EIN                       34299\n",
       "NAME                      19568\n",
       "APPLICATION_TYPE             17\n",
       "AFFILIATION                   6\n",
       "CLASSIFICATION               71\n",
       "USE_CASE                      5\n",
       "ORGANIZATION                  4\n",
       "STATUS                        2\n",
       "INCOME_AMT                    9\n",
       "SPECIAL_CONSIDERATIONS        2\n",
       "ASK_AMT                    8747\n",
       "IS_SUCCESSFUL                 2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdata_df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis\n",
    "\n",
    "- EIN - Employeer Identifier Number is a unique identifier per org, discrete\n",
    "- STATUS - values 0 or 1\n",
    "- ASK_AMT - continuous\n",
    "- IS_SUCCESSFUL - values 0 or 1\n",
    "\n",
    "Using the provided column descriptions and the above initial analysis we can answer the questions.\n",
    "\n",
    "What variable(s) are considered the target for your model?\n",
    "- IS_SUCCESSFUL\n",
    "\n",
    "What variable(s) are considered to be the features for your model?\n",
    "- ASK_AMT\n",
    "- AFFILIATION\n",
    "- CLASSIFICATION\n",
    "- USE_CASE\n",
    "- ORGANIZATION\n",
    "- INCOME_AMT - NOTE look like bucket categories\n",
    "\n",
    "What variable(s) are neither and should be removed from the input data?\n",
    "- EIN and NAME \n",
    "- STATUS\n",
    "- SPECIAL_CONSIDERATIONS\n",
    "- APPLICATION_TYPE\n",
    "\n",
    "NOTE: Consider the immediate above data types as non-features because they appear to be administrative codes applied to rather than discenrable attributes of the organizations. We can revisit this assumption depending on the results of the analysys. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION     INCOME_AMT  \\\n",
       "0       Independent          C1000    ProductDev   Association              0   \n",
       "1       Independent          C2000  Preservation  Co-operative         1-9999   \n",
       "2  CompanySponsored          C3000    ProductDev   Association              0   \n",
       "3  CompanySponsored          C2000  Preservation         Trust    10000-24999   \n",
       "4       Independent          C1000     Heathcare         Trust  100000-499999   \n",
       "\n",
       "   ASK_AMT  IS_SUCCESSFUL  \n",
       "0     5000              1  \n",
       "1   108590              1  \n",
       "2     5000              0  \n",
       "3     6692              1  \n",
       "4   142590              1  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep org rows where STATUS == 1 and drop the rest, STATUS == 0 indicating NOT Active\n",
    "cleandata_df = rawdata_df.loc[rawdata_df[\"STATUS\"] == 1]\n",
    "\n",
    "# Drop columns that are neither features nor targets from the dataset\n",
    "cleandata_df = cleandata_df.drop(columns=[\"EIN\", \"NAME\", \"SPECIAL_CONSIDERATIONS\", \"APPLICATION_TYPE\", \"STATUS\"])\n",
    "\n",
    "cleandata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34294, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AFFILIATION       object\n",
       "CLASSIFICATION    object\n",
       "USE_CASE          object\n",
       "ORGANIZATION      object\n",
       "INCOME_AMT        object\n",
       "ASK_AMT            int64\n",
       "IS_SUCCESSFUL      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape and types of the dataframe\n",
    "print(cleandata_df.shape)\n",
    "cleandata_df.dtypes\n",
    "\n",
    "# Dropped five rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the data \n",
    "Using the methods described in this module, preprocess all numerical and categorical variables, as needed\n",
    "\n",
    "- Combine rare categorical values via bucketing.\n",
    "- Encode categorical variables using one-hot encoding.\n",
    "- Standardize numerical variables using Scikit-Learn’s StandardScaler class.\n",
    "\n",
    "### Combine rare categorical values via bucketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AFFILIATION', 'CLASSIFICATION', 'USE_CASE', 'ORGANIZATION', 'INCOME_AMT']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Generate a categorical variable list\n",
    "cleandata_cat = cleandata_df.dtypes[cleandata_df.dtypes == \"object\"].index.tolist()\n",
    "cleandata_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AFFILIATION       6\n",
       "CLASSIFICATION    6\n",
       "USE_CASE          5\n",
       "ORGANIZATION      4\n",
       "INCOME_AMT        9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the number of unique values in each column\n",
    "cleandata_df[cleandata_cat].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1000    17323\n",
      "C2000     6073\n",
      "C1200     4837\n",
      "Other     2261\n",
      "C3000     1918\n",
      "C2100     1882\n",
      "Name: CLASSIFICATION, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ffa51142690>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using the commonly used limit of 10 to determine which categorical lists should be bucketed, \n",
    "# we will bucket only the \"CLASSIFICATION\" column\n",
    "\n",
    "# Visualize the value counts\n",
    "classification_counts = cleandata_df.CLASSIFICATION.value_counts()\n",
    "print(classification_counts)\n",
    "\n",
    "classification_counts.plot.density()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most straightforward method to determine a bucket threshold is to use a density plot to identify where the value counts “fall off” and set the threshold within this region.\n",
    "\n",
    "From the density plot, visual inspection indicates the fall off is at about 1000 - 2000 instances within the dataset. That will be our bucket limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17323\n",
       "C2000     6073\n",
       "C1200     4837\n",
       "Other     2261\n",
       "C3000     1918\n",
       "C2100     1882\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify those category's with values less than the threshold of 1500 will be bucketed\n",
    "replace_classification = list(classification_counts[classification_counts < 1500].index)\n",
    "\n",
    "# Replace those classification category items with counts less than the threshold identified above\n",
    "for classification in replace_classification:\n",
    "    cleandata_df.CLASSIFICATION = cleandata_df.CLASSIFICATION.replace(classification,\"Other\")\n",
    "\n",
    "# Inspect the result of binning to confirm it produced a useful result\n",
    "# In this case we reduced the number of CLASSIFICATION items from 71 to 6 \n",
    "cleandata_df.CLASSIFICATION.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Encode categorical variables using one-hot encoding\n",
    "\n",
    "We have reduced the number of unique values in the CLASSIFICATION variable, now transpose the text variables using one-hot encoding using Scikit-learn’s OneHotEncoder module. To build the encoded columns, create an instance of OneHotEncoder and “fit” the encoder with our values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['AFFILIATION_CompanySponsored', 'AFFILIATION_Family/Parent',\n",
      "       'AFFILIATION_Independent', 'AFFILIATION_National', 'AFFILIATION_Other',\n",
      "       'AFFILIATION_Regional', 'CLASSIFICATION_C1000', 'CLASSIFICATION_C1200',\n",
      "       'CLASSIFICATION_C2000', 'CLASSIFICATION_C2100', 'CLASSIFICATION_C3000',\n",
      "       'CLASSIFICATION_Other', 'USE_CASE_CommunityServ', 'USE_CASE_Heathcare',\n",
      "       'USE_CASE_Other', 'USE_CASE_Preservation', 'USE_CASE_ProductDev',\n",
      "       'ORGANIZATION_Association', 'ORGANIZATION_Co-operative',\n",
      "       'ORGANIZATION_Corporation', 'ORGANIZATION_Trust', 'INCOME_AMT_0',\n",
      "       'INCOME_AMT_1-9999', 'INCOME_AMT_10000-24999',\n",
      "       'INCOME_AMT_100000-499999', 'INCOME_AMT_10M-50M', 'INCOME_AMT_1M-5M',\n",
      "       'INCOME_AMT_25000-99999', 'INCOME_AMT_50M+', 'INCOME_AMT_5M-10M'],\n",
      "      dtype='object')\n",
      "AFFILIATION_CompanySponsored    float64\n",
      "AFFILIATION_Family/Parent       float64\n",
      "AFFILIATION_Independent         float64\n",
      "AFFILIATION_National            float64\n",
      "AFFILIATION_Other               float64\n",
      "AFFILIATION_Regional            float64\n",
      "CLASSIFICATION_C1000            float64\n",
      "CLASSIFICATION_C1200            float64\n",
      "CLASSIFICATION_C2000            float64\n",
      "CLASSIFICATION_C2100            float64\n",
      "CLASSIFICATION_C3000            float64\n",
      "CLASSIFICATION_Other            float64\n",
      "USE_CASE_CommunityServ          float64\n",
      "USE_CASE_Heathcare              float64\n",
      "USE_CASE_Other                  float64\n",
      "USE_CASE_Preservation           float64\n",
      "USE_CASE_ProductDev             float64\n",
      "ORGANIZATION_Association        float64\n",
      "ORGANIZATION_Co-operative       float64\n",
      "ORGANIZATION_Corporation        float64\n",
      "ORGANIZATION_Trust              float64\n",
      "INCOME_AMT_0                    float64\n",
      "INCOME_AMT_1-9999               float64\n",
      "INCOME_AMT_10000-24999          float64\n",
      "INCOME_AMT_100000-499999        float64\n",
      "INCOME_AMT_10M-50M              float64\n",
      "INCOME_AMT_1M-5M                float64\n",
      "INCOME_AMT_25000-99999          float64\n",
      "INCOME_AMT_50M+                 float64\n",
      "INCOME_AMT_5M-10M               float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>AFFILIATION_Family/Parent</th>\n",
       "      <th>AFFILIATION_Independent</th>\n",
       "      <th>AFFILIATION_National</th>\n",
       "      <th>AFFILIATION_Other</th>\n",
       "      <th>AFFILIATION_Regional</th>\n",
       "      <th>CLASSIFICATION_C1000</th>\n",
       "      <th>CLASSIFICATION_C1200</th>\n",
       "      <th>CLASSIFICATION_C2000</th>\n",
       "      <th>CLASSIFICATION_C2100</th>\n",
       "      <th>...</th>\n",
       "      <th>ORGANIZATION_Trust</th>\n",
       "      <th>INCOME_AMT_0</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AFFILIATION_CompanySponsored  AFFILIATION_Family/Parent  \\\n",
       "0                           0.0                        0.0   \n",
       "1                           0.0                        0.0   \n",
       "2                           1.0                        0.0   \n",
       "3                           1.0                        0.0   \n",
       "4                           0.0                        0.0   \n",
       "\n",
       "   AFFILIATION_Independent  AFFILIATION_National  AFFILIATION_Other  \\\n",
       "0                      1.0                   0.0                0.0   \n",
       "1                      1.0                   0.0                0.0   \n",
       "2                      0.0                   0.0                0.0   \n",
       "3                      0.0                   0.0                0.0   \n",
       "4                      1.0                   0.0                0.0   \n",
       "\n",
       "   AFFILIATION_Regional  CLASSIFICATION_C1000  CLASSIFICATION_C1200  \\\n",
       "0                   0.0                   1.0                   0.0   \n",
       "1                   0.0                   0.0                   0.0   \n",
       "2                   0.0                   0.0                   0.0   \n",
       "3                   0.0                   0.0                   0.0   \n",
       "4                   0.0                   1.0                   0.0   \n",
       "\n",
       "   CLASSIFICATION_C2000  CLASSIFICATION_C2100  ...  ORGANIZATION_Trust  \\\n",
       "0                   0.0                   0.0  ...                 0.0   \n",
       "1                   1.0                   0.0  ...                 0.0   \n",
       "2                   0.0                   0.0  ...                 0.0   \n",
       "3                   1.0                   0.0  ...                 1.0   \n",
       "4                   0.0                   0.0  ...                 1.0   \n",
       "\n",
       "   INCOME_AMT_0  INCOME_AMT_1-9999  INCOME_AMT_10000-24999  \\\n",
       "0           1.0                0.0                     0.0   \n",
       "1           0.0                1.0                     0.0   \n",
       "2           1.0                0.0                     0.0   \n",
       "3           0.0                0.0                     1.0   \n",
       "4           0.0                0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  \\\n",
       "0                       0.0                 0.0               0.0   \n",
       "1                       0.0                 0.0               0.0   \n",
       "2                       0.0                 0.0               0.0   \n",
       "3                       0.0                 0.0               0.0   \n",
       "4                       1.0                 0.0               0.0   \n",
       "\n",
       "   INCOME_AMT_25000-99999  INCOME_AMT_50M+  INCOME_AMT_5M-10M  \n",
       "0                     0.0              0.0                0.0  \n",
       "1                     0.0              0.0                0.0  \n",
       "2                     0.0              0.0                0.0  \n",
       "3                     0.0              0.0                0.0  \n",
       "4                     0.0              0.0                0.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(cleandata_df[cleandata_cat]))\n",
    "encode_df\n",
    "\n",
    "# Add the encoded variable names to the DataFrame\n",
    "encode_df.columns = enc.get_feature_names(cleandata_cat)\n",
    "print(encode_df.columns)\n",
    "print(encode_df.dtypes)\n",
    "encode_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34289, 32)\n",
      "ASK_AMT                           int64\n",
      "IS_SUCCESSFUL                     int64\n",
      "AFFILIATION_CompanySponsored    float64\n",
      "AFFILIATION_Family/Parent       float64\n",
      "AFFILIATION_Independent         float64\n",
      "AFFILIATION_National            float64\n",
      "AFFILIATION_Other               float64\n",
      "AFFILIATION_Regional            float64\n",
      "CLASSIFICATION_C1000            float64\n",
      "CLASSIFICATION_C1200            float64\n",
      "CLASSIFICATION_C2000            float64\n",
      "CLASSIFICATION_C2100            float64\n",
      "CLASSIFICATION_C3000            float64\n",
      "CLASSIFICATION_Other            float64\n",
      "USE_CASE_CommunityServ          float64\n",
      "USE_CASE_Heathcare              float64\n",
      "USE_CASE_Other                  float64\n",
      "USE_CASE_Preservation           float64\n",
      "USE_CASE_ProductDev             float64\n",
      "ORGANIZATION_Association        float64\n",
      "ORGANIZATION_Co-operative       float64\n",
      "ORGANIZATION_Corporation        float64\n",
      "ORGANIZATION_Trust              float64\n",
      "INCOME_AMT_0                    float64\n",
      "INCOME_AMT_1-9999               float64\n",
      "INCOME_AMT_10000-24999          float64\n",
      "INCOME_AMT_100000-499999        float64\n",
      "INCOME_AMT_10M-50M              float64\n",
      "INCOME_AMT_1M-5M                float64\n",
      "INCOME_AMT_25000-99999          float64\n",
      "INCOME_AMT_50M+                 float64\n",
      "INCOME_AMT_5M-10M               float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>AFFILIATION_Family/Parent</th>\n",
       "      <th>AFFILIATION_Independent</th>\n",
       "      <th>AFFILIATION_National</th>\n",
       "      <th>AFFILIATION_Other</th>\n",
       "      <th>AFFILIATION_Regional</th>\n",
       "      <th>CLASSIFICATION_C1000</th>\n",
       "      <th>CLASSIFICATION_C1200</th>\n",
       "      <th>...</th>\n",
       "      <th>ORGANIZATION_Trust</th>\n",
       "      <th>INCOME_AMT_0</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ASK_AMT  IS_SUCCESSFUL  AFFILIATION_CompanySponsored  \\\n",
       "0     5000              1                           0.0   \n",
       "1   108590              1                           0.0   \n",
       "2     5000              0                           1.0   \n",
       "3     6692              1                           1.0   \n",
       "4   142590              1                           0.0   \n",
       "\n",
       "   AFFILIATION_Family/Parent  AFFILIATION_Independent  AFFILIATION_National  \\\n",
       "0                        0.0                      1.0                   0.0   \n",
       "1                        0.0                      1.0                   0.0   \n",
       "2                        0.0                      0.0                   0.0   \n",
       "3                        0.0                      0.0                   0.0   \n",
       "4                        0.0                      1.0                   0.0   \n",
       "\n",
       "   AFFILIATION_Other  AFFILIATION_Regional  CLASSIFICATION_C1000  \\\n",
       "0                0.0                   0.0                   1.0   \n",
       "1                0.0                   0.0                   0.0   \n",
       "2                0.0                   0.0                   0.0   \n",
       "3                0.0                   0.0                   0.0   \n",
       "4                0.0                   0.0                   1.0   \n",
       "\n",
       "   CLASSIFICATION_C1200  ...  ORGANIZATION_Trust  INCOME_AMT_0  \\\n",
       "0                   0.0  ...                 0.0           1.0   \n",
       "1                   0.0  ...                 0.0           0.0   \n",
       "2                   0.0  ...                 0.0           1.0   \n",
       "3                   0.0  ...                 1.0           0.0   \n",
       "4                   0.0  ...                 1.0           0.0   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                0.0                     0.0                       0.0   \n",
       "1                1.0                     0.0                       0.0   \n",
       "2                0.0                     0.0                       0.0   \n",
       "3                0.0                     1.0                       0.0   \n",
       "4                0.0                     0.0                       1.0   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                 0.0               0.0                     0.0   \n",
       "1                 0.0               0.0                     0.0   \n",
       "2                 0.0               0.0                     0.0   \n",
       "3                 0.0               0.0                     0.0   \n",
       "4                 0.0               0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  \n",
       "0              0.0                0.0  \n",
       "1              0.0                0.0  \n",
       "2              0.0                0.0  \n",
       "3              0.0                0.0  \n",
       "4              0.0                0.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge one-hot encoded features into the cleandata_df and drop the original columns\n",
    "encodedata_df = cleandata_df.merge(encode_df,left_index=True, right_index=True)\n",
    "encodedata_df = encodedata_df.drop(cleandata_cat,1)\n",
    "print(encodedata_df.shape)\n",
    "print(encodedata_df.dtypes)\n",
    "encodedata_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Standardize numerical variables using Scikit-Learn’s StandardScaler class.\n",
    "\n",
    "Neural network models can interpret and evaluate all forms of numeric data. Even though a neural network can train on raw numerical data, it does not mean that it should train on raw data. There are many reasons why a raw numeric variable is insufficient for use when training a neural network model, such as:\n",
    "\n",
    "- Raw data often has outliers or extreme values that can artificially inflate a variable’s importance.\n",
    "- Numerical data can be measured using different units across a dataset—such as time versus temperature, or length versus volume.\n",
    "- The distribution of a variable can be skewed, leading to misinterpretation of the central tendency.\n",
    "\n",
    "We will minimize this risk by **standardizing** (also commonly referred to as **normalization**) the numerical data prior to training using Scikit-learn’s StandardScaler module, to standardize numerical data such that a variable is rescaled to a mean of 0 and standard deviation of 1.\n",
    "\n",
    "We will standardize our numerical variables to reduce the overall likelihood that outliers, variables of different units, or skewed distributions will have a negative impact on the model’s performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the StandardScaler instance\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEFORE scaling prepare the train and test data \n",
    "\n",
    "Seperate the TARGET data out of the FEATURES data before scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assign the TARGET data y\n",
    "y = encodedata_df.IS_SUCCESSFUL\n",
    "# Remove \"IS_SUCCESSFUL\" target data from features data and assign to X\n",
    "X = encodedata_df.drop(columns=[\"IS_SUCCESSFUL\"])\n",
    "\n",
    "# Split training/test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25716, 31)\n",
      "(8573, 31)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate StandardScaler to fit the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# StandardScaler instance is fitted with the numerical data, transform and standardize the dataset\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "print(X_train_scaled.shape)\n",
    "print(X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network design considerations\n",
    "\n",
    "Use a TensorFlow neural network design to create a binary classification model that predicts if an Alphabet Soup funded organization will be successful, based on the features in the dataset.\n",
    "\n",
    "- use a neural network or deep learning model\n",
    "- Consider the number of inputs before determining the number of neurons and layers in your model\n",
    "\n",
    "Compile, train, and evaluate the binary classification model, producing the following outputs:\n",
    "\n",
    "- Final model loss metric\n",
    "- Final model predictive accuracy\n",
    "- Attempt to optimize the model training and input data to achieve a target predictive accuracy higher than 75%\n",
    "\n",
    "\n",
    "### Initial model choice - Deep Learning Neural Net\n",
    "- Input layer - set the number of input features equal to the number of variables in the feature DataFrame\n",
    "- Hidden layers - ONE hidden layer with TWICE the number of neurons as the input layer\n",
    "- Second hidden layer - NOT initially\n",
    "- all layers use a Keras Dense class\n",
    "- All of the hidden layers use the relu activation function to identify nonlinear characteristics from the input values.\n",
    "- Output layer - use the the sigmoid activation function\n",
    "- The Sigmoid Activation function will help predict the probability that Alphabet Soup funded organization will be successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25716 samples\n",
      "Epoch 1/50\n",
      "25716/25716 [==============================] - 2s 66us/sample - loss: 0.6933 - accuracy: 0.5562\n",
      "Epoch 2/50\n",
      "25716/25716 [==============================] - 1s 42us/sample - loss: 0.6856 - accuracy: 0.5642\n",
      "Epoch 3/50\n",
      "25716/25716 [==============================] - 1s 42us/sample - loss: 0.6840 - accuracy: 0.5679\n",
      "Epoch 4/50\n",
      "25716/25716 [==============================] - 1s 44us/sample - loss: 0.6836 - accuracy: 0.5689\n",
      "Epoch 5/50\n",
      "25716/25716 [==============================] - 1s 42us/sample - loss: 0.6829 - accuracy: 0.5696\n",
      "Epoch 6/50\n",
      "25716/25716 [==============================] - 1s 44us/sample - loss: 0.6828 - accuracy: 0.5703\n",
      "Epoch 7/50\n",
      "25716/25716 [==============================] - 1s 45us/sample - loss: 0.6825 - accuracy: 0.5700\n",
      "Epoch 8/50\n",
      "25716/25716 [==============================] - 1s 42us/sample - loss: 0.6818 - accuracy: 0.5722\n",
      "Epoch 9/50\n",
      "25716/25716 [==============================] - 1s 42us/sample - loss: 0.6818 - accuracy: 0.5700\n",
      "Epoch 10/50\n",
      "25716/25716 [==============================] - 1s 44us/sample - loss: 0.6812 - accuracy: 0.5720\n",
      "Epoch 11/50\n",
      "25716/25716 [==============================] - 1s 43us/sample - loss: 0.6812 - accuracy: 0.5719\n",
      "Epoch 12/50\n",
      "25716/25716 [==============================] - 1s 46us/sample - loss: 0.6810 - accuracy: 0.5710\n",
      "Epoch 13/50\n",
      "25716/25716 [==============================] - 1s 45us/sample - loss: 0.6813 - accuracy: 0.5714\n",
      "Epoch 14/50\n",
      "25716/25716 [==============================] - 1s 45us/sample - loss: 0.6811 - accuracy: 0.5750\n",
      "Epoch 15/50\n",
      "25716/25716 [==============================] - 1s 44us/sample - loss: 0.6809 - accuracy: 0.5732\n",
      "Epoch 16/50\n",
      "25716/25716 [==============================] - 1s 43us/sample - loss: 0.6806 - accuracy: 0.5719\n",
      "Epoch 17/50\n",
      "25716/25716 [==============================] - 2s 62us/sample - loss: 0.6810 - accuracy: 0.5716\n",
      "Epoch 18/50\n",
      "25716/25716 [==============================] - 1s 46us/sample - loss: 0.6806 - accuracy: 0.5718\n",
      "Epoch 19/50\n",
      "25716/25716 [==============================] - 2s 72us/sample - loss: 0.6806 - accuracy: 0.5737\n",
      "Epoch 20/50\n",
      "25716/25716 [==============================] - 1s 48us/sample - loss: 0.6806 - accuracy: 0.5733\n",
      "Epoch 21/50\n",
      "25716/25716 [==============================] - 1s 42us/sample - loss: 0.6805 - accuracy: 0.5746\n",
      "Epoch 22/50\n",
      "25716/25716 [==============================] - 1s 43us/sample - loss: 0.6799 - accuracy: 0.5726\n",
      "Epoch 23/50\n",
      "25716/25716 [==============================] - 1s 47us/sample - loss: 0.6801 - accuracy: 0.5749\n",
      "Epoch 24/50\n",
      "25716/25716 [==============================] - 1s 49us/sample - loss: 0.6801 - accuracy: 0.5727\n",
      "Epoch 25/50\n",
      "25716/25716 [==============================] - 1s 49us/sample - loss: 0.6799 - accuracy: 0.5735\n",
      "Epoch 26/50\n",
      "25716/25716 [==============================] - 1s 45us/sample - loss: 0.6799 - accuracy: 0.5726\n",
      "Epoch 27/50\n",
      "25716/25716 [==============================] - 1s 44us/sample - loss: 0.6802 - accuracy: 0.5731\n",
      "Epoch 28/50\n",
      "25716/25716 [==============================] - 1s 46us/sample - loss: 0.6797 - accuracy: 0.5756\n",
      "Epoch 29/50\n",
      "25716/25716 [==============================] - 1s 43us/sample - loss: 0.6797 - accuracy: 0.5739\n",
      "Epoch 30/50\n",
      "25716/25716 [==============================] - 1s 49us/sample - loss: 0.6800 - accuracy: 0.5742\n",
      "Epoch 31/50\n",
      "25716/25716 [==============================] - 1s 46us/sample - loss: 0.6798 - accuracy: 0.5736\n",
      "Epoch 32/50\n",
      "25716/25716 [==============================] - 1s 44us/sample - loss: 0.6796 - accuracy: 0.5744\n",
      "Epoch 33/50\n",
      "25716/25716 [==============================] - 1s 45us/sample - loss: 0.6794 - accuracy: 0.5743\n",
      "Epoch 34/50\n",
      "25716/25716 [==============================] - 1s 43us/sample - loss: 0.6801 - accuracy: 0.5734\n",
      "Epoch 35/50\n",
      "25716/25716 [==============================] - 1s 46us/sample - loss: 0.6795 - accuracy: 0.5737\n",
      "Epoch 36/50\n",
      "25716/25716 [==============================] - 1s 44us/sample - loss: 0.6796 - accuracy: 0.5756\n",
      "Epoch 37/50\n",
      "25716/25716 [==============================] - 1s 45us/sample - loss: 0.6797 - accuracy: 0.5766\n",
      "Epoch 38/50\n",
      "25716/25716 [==============================] - 1s 43us/sample - loss: 0.6794 - accuracy: 0.5744\n",
      "Epoch 39/50\n",
      "25716/25716 [==============================] - 1s 44us/sample - loss: 0.6796 - accuracy: 0.5754\n",
      "Epoch 40/50\n",
      "25716/25716 [==============================] - 1s 48us/sample - loss: 0.6792 - accuracy: 0.5743\n",
      "Epoch 41/50\n",
      "25716/25716 [==============================] - 1s 43us/sample - loss: 0.6792 - accuracy: 0.5744\n",
      "Epoch 42/50\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6794 - accuracy: 0.5758\n",
      "Epoch 43/50\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6793 - accuracy: 0.5757\n",
      "Epoch 44/50\n",
      "25716/25716 [==============================] - 1s 44us/sample - loss: 0.6794 - accuracy: 0.5745\n",
      "Epoch 45/50\n",
      "25716/25716 [==============================] - 1s 43us/sample - loss: 0.6793 - accuracy: 0.5762\n",
      "Epoch 46/50\n",
      "25716/25716 [==============================] - 1s 43us/sample - loss: 0.6793 - accuracy: 0.5761\n",
      "Epoch 47/50\n",
      "25716/25716 [==============================] - 1s 43us/sample - loss: 0.6793 - accuracy: 0.5738\n",
      "Epoch 48/50\n",
      "25716/25716 [==============================] - 1s 44us/sample - loss: 0.6791 - accuracy: 0.5761\n",
      "Epoch 49/50\n",
      "25716/25716 [==============================] - 1s 43us/sample - loss: 0.6789 - accuracy: 0.5759\n",
      "Epoch 50/50\n",
      "25716/25716 [==============================] - 1s 43us/sample - loss: 0.6790 - accuracy: 0.5759\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "# We will start with a ratio of 2 to 1 for the input to hidden layer number of neurons\n",
    "hidden_nodes_layer1 = len(X_train_scaled[0])*2\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# The hidden layer uses ReLU activation function to enable nonlinear relationships\n",
    "# however the classification output uses a sigmoid activation function to produce a probability output\n",
    "# The classification model wants a yes or no binary decision; therefore, we only need one output neuron\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "# loss function binary_crossentropy is specifically designed to evaluate a binary classification model\n",
    "# adam optimizer uses a gradient descent approach to ensure that the algorithm will not get stuck on weaker classifying variables and features\n",
    "# Use evaluation metric of accuracy is used for classification models\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, numpy.array(y_train), epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff87cc03c10>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame containing training history\n",
    "history_df = pd.DataFrame(fit_model.history, index=range(1,len(fit_model.history[\"loss\"])+1))\n",
    "\n",
    "# Plot the loss\n",
    "# loss metric - used by machine learning algorithms to score the performance of the model through each iteration \n",
    "# and epoch by evaluating the inaccuracy of a single input.\n",
    "history_df.plot(y=\"loss\")\n",
    "# Plot the accuracy\n",
    "# For model predictive accuracy, the higher the number the better, \n",
    "history_df.plot(y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_51 (Dense)             (None, 62)                1984      \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 1)                 63        \n",
      "=================================================================\n",
      "Total params: 2,047\n",
      "Trainable params: 2,047\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check the model summary\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8573/1 - 0s - loss: 0.6851 - accuracy: 0.5628\n",
      "Loss: 0.6855217874724543, Accuracy: 0.5628134608268738\n"
     ]
    }
   ],
   "source": [
    "# Use the test dataset to evaluate this first version of the model\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, numpy.array(y_test), verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial model variation conculsion\n",
    "The target predictive accuracy is **less than 75%** (at 56%), we will try to improve the model.\n",
    "\n",
    "8573/1 - 0s - loss: 0.6851 - accuracy: 0.5628\n",
    "\n",
    "Loss: 0.6855217874724543, Accuracy: 0.5628134608268738"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvment attempt - increase ratio of neurons in first hidden layer from 2 to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25716 samples\n",
      "Epoch 1/50\n",
      "25716/25716 [==============================] - 2s 68us/sample - loss: 0.6918 - accuracy: 0.5535\n",
      "Epoch 2/50\n",
      "25716/25716 [==============================] - 1s 45us/sample - loss: 0.6853 - accuracy: 0.5642\n",
      "Epoch 3/50\n",
      "25716/25716 [==============================] - 1s 49us/sample - loss: 0.6849 - accuracy: 0.5673\n",
      "Epoch 4/50\n",
      "25716/25716 [==============================] - 1s 48us/sample - loss: 0.6832 - accuracy: 0.5678\n",
      "Epoch 5/50\n",
      "25716/25716 [==============================] - 1s 45us/sample - loss: 0.6829 - accuracy: 0.5689\n",
      "Epoch 6/50\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6826 - accuracy: 0.5682\n",
      "Epoch 7/50\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6826 - accuracy: 0.5708\n",
      "Epoch 8/50\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6826 - accuracy: 0.5693\n",
      "Epoch 9/50\n",
      "25716/25716 [==============================] - 1s 42us/sample - loss: 0.6820 - accuracy: 0.5656\n",
      "Epoch 10/50\n",
      "25716/25716 [==============================] - 1s 45us/sample - loss: 0.6819 - accuracy: 0.5703\n",
      "Epoch 11/50\n",
      "25716/25716 [==============================] - 1s 42us/sample - loss: 0.6815 - accuracy: 0.5695\n",
      "Epoch 12/50\n",
      "25716/25716 [==============================] - 1s 43us/sample - loss: 0.6819 - accuracy: 0.5714\n",
      "Epoch 13/50\n",
      "25716/25716 [==============================] - 1s 45us/sample - loss: 0.6812 - accuracy: 0.5696\n",
      "Epoch 14/50\n",
      "25716/25716 [==============================] - 1s 42us/sample - loss: 0.6811 - accuracy: 0.5726\n",
      "Epoch 15/50\n",
      "25716/25716 [==============================] - 1s 42us/sample - loss: 0.6814 - accuracy: 0.5712\n",
      "Epoch 16/50\n",
      "25716/25716 [==============================] - 1s 43us/sample - loss: 0.6811 - accuracy: 0.5710\n",
      "Epoch 17/50\n",
      "25716/25716 [==============================] - 1s 41us/sample - loss: 0.6808 - accuracy: 0.5722\n",
      "Epoch 18/50\n",
      "25716/25716 [==============================] - 1s 42us/sample - loss: 0.6809 - accuracy: 0.5723\n",
      "Epoch 19/50\n",
      "25716/25716 [==============================] - 1s 41us/sample - loss: 0.6803 - accuracy: 0.5728\n",
      "Epoch 20/50\n",
      "25716/25716 [==============================] - 1s 41us/sample - loss: 0.6807 - accuracy: 0.5742\n",
      "Epoch 21/50\n",
      "25716/25716 [==============================] - 1s 41us/sample - loss: 0.6804 - accuracy: 0.5721\n",
      "Epoch 22/50\n",
      "25716/25716 [==============================] - 1s 41us/sample - loss: 0.6804 - accuracy: 0.5733\n",
      "Epoch 23/50\n",
      "25716/25716 [==============================] - 1s 42us/sample - loss: 0.6802 - accuracy: 0.5731\n",
      "Epoch 24/50\n",
      "25716/25716 [==============================] - 1s 41us/sample - loss: 0.6802 - accuracy: 0.5715\n",
      "Epoch 25/50\n",
      "25716/25716 [==============================] - 1s 42us/sample - loss: 0.6804 - accuracy: 0.5747\n",
      "Epoch 26/50\n",
      "25716/25716 [==============================] - 1s 41us/sample - loss: 0.6799 - accuracy: 0.5735\n",
      "Epoch 27/50\n",
      "25716/25716 [==============================] - 1s 43us/sample - loss: 0.6798 - accuracy: 0.5741\n",
      "Epoch 28/50\n",
      "25716/25716 [==============================] - 1s 44us/sample - loss: 0.6798 - accuracy: 0.5749\n",
      "Epoch 29/50\n",
      "25716/25716 [==============================] - 1s 42us/sample - loss: 0.6798 - accuracy: 0.5741\n",
      "Epoch 30/50\n",
      "25716/25716 [==============================] - 1s 49us/sample - loss: 0.6802 - accuracy: 0.5736\n",
      "Epoch 31/50\n",
      "25716/25716 [==============================] - 1s 46us/sample - loss: 0.6801 - accuracy: 0.5737\n",
      "Epoch 32/50\n",
      "25716/25716 [==============================] - 1s 47us/sample - loss: 0.6798 - accuracy: 0.5743\n",
      "Epoch 33/50\n",
      "25716/25716 [==============================] - 1s 43us/sample - loss: 0.6797 - accuracy: 0.5747\n",
      "Epoch 34/50\n",
      "25716/25716 [==============================] - 1s 44us/sample - loss: 0.6789 - accuracy: 0.5756\n",
      "Epoch 35/50\n",
      "25716/25716 [==============================] - 1s 42us/sample - loss: 0.6794 - accuracy: 0.5754\n",
      "Epoch 36/50\n",
      "25716/25716 [==============================] - 1s 46us/sample - loss: 0.6797 - accuracy: 0.5746\n",
      "Epoch 37/50\n",
      "25716/25716 [==============================] - 1s 48us/sample - loss: 0.6791 - accuracy: 0.5755\n",
      "Epoch 38/50\n",
      "25716/25716 [==============================] - 1s 45us/sample - loss: 0.6790 - accuracy: 0.5743\n",
      "Epoch 39/50\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6795 - accuracy: 0.5757\n",
      "Epoch 40/50\n",
      "25716/25716 [==============================] - 1s 44us/sample - loss: 0.6794 - accuracy: 0.5760\n",
      "Epoch 41/50\n",
      "25716/25716 [==============================] - 1s 40us/sample - loss: 0.6789 - accuracy: 0.5765\n",
      "Epoch 42/50\n",
      "25716/25716 [==============================] - 1s 42us/sample - loss: 0.6792 - accuracy: 0.5742\n",
      "Epoch 43/50\n",
      "25716/25716 [==============================] - 1s 41us/sample - loss: 0.6789 - accuracy: 0.5735\n",
      "Epoch 44/50\n",
      "25716/25716 [==============================] - 1s 42us/sample - loss: 0.6790 - accuracy: 0.5760\n",
      "Epoch 45/50\n",
      "25716/25716 [==============================] - 1s 41us/sample - loss: 0.6789 - accuracy: 0.5763\n",
      "Epoch 46/50\n",
      "25716/25716 [==============================] - 1s 41us/sample - loss: 0.6793 - accuracy: 0.5755\n",
      "Epoch 47/50\n",
      "25716/25716 [==============================] - 1s 43us/sample - loss: 0.6789 - accuracy: 0.5734\n",
      "Epoch 48/50\n",
      "25716/25716 [==============================] - 1s 42us/sample - loss: 0.6787 - accuracy: 0.5751\n",
      "Epoch 49/50\n",
      "25716/25716 [==============================] - 1s 42us/sample - loss: 0.6787 - accuracy: 0.5752\n",
      "Epoch 50/50\n",
      "25716/25716 [==============================] - 1s 42us/sample - loss: 0.6790 - accuracy: 0.5755\n",
      "8573/1 - 0s - loss: 0.6823 - accuracy: 0.5585\n",
      "Loss: 0.6862653077142347, Accuracy: 0.5584976077079773\n"
     ]
    }
   ],
   "source": [
    "# Increase the ratio of number of hidden to input layer neurons\n",
    "hidden_nodes_layer1 = len(X_train_scaled[0])*3\n",
    "\n",
    "# The remained of the model remains the sameDefine\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "nn = tf.keras.models.Sequential()\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "fit_model = nn.fit(X_train_scaled, numpy.array(y_train), epochs=50)\n",
    "\n",
    "# Use the test dataset to evaluate this version of the model\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, numpy.array(y_test), verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy is 56%\n",
    "\n",
    "8573/1 - 0s - loss: 0.6823 - accuracy: 0.5585\n",
    "        \n",
    "Loss: 0.6862653077142347, Accuracy: 0.5584976077079773"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff93968e7d0>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Update training history\n",
    "history_df = pd.DataFrame(fit_model.history, index=range(1,len(fit_model.history[\"loss\"])+1))\n",
    "# Plot the loss\n",
    "history_df.plot(y=\"loss\")\n",
    "# Plot the accuracy\n",
    "history_df.plot(y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increase ratio from 3 to 4 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25716 samples\n",
      "Epoch 1/50\n",
      "25716/25716 [==============================] - 2s 66us/sample - loss: 0.6897 - accuracy: 0.5618\n",
      "Epoch 2/50\n",
      "25716/25716 [==============================] - 1s 44us/sample - loss: 0.6861 - accuracy: 0.5646\n",
      "Epoch 3/50\n",
      "25716/25716 [==============================] - 1s 56us/sample - loss: 0.6844 - accuracy: 0.5651\n",
      "Epoch 4/50\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6844 - accuracy: 0.5653\n",
      "Epoch 5/50\n",
      "25716/25716 [==============================] - 1s 48us/sample - loss: 0.6836 - accuracy: 0.5674\n",
      "Epoch 6/50\n",
      "25716/25716 [==============================] - 2s 69us/sample - loss: 0.6834 - accuracy: 0.5661\n",
      "Epoch 7/50\n",
      "25716/25716 [==============================] - 2s 60us/sample - loss: 0.6823 - accuracy: 0.5708\n",
      "Epoch 8/50\n",
      "25716/25716 [==============================] - 1s 47us/sample - loss: 0.6828 - accuracy: 0.5694\n",
      "Epoch 9/50\n",
      "25716/25716 [==============================] - 1s 58us/sample - loss: 0.6826 - accuracy: 0.5703\n",
      "Epoch 10/50\n",
      "25716/25716 [==============================] - 2s 63us/sample - loss: 0.6821 - accuracy: 0.5688\n",
      "Epoch 11/50\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6815 - accuracy: 0.5713\n",
      "Epoch 12/50\n",
      "25716/25716 [==============================] - 1s 48us/sample - loss: 0.6813 - accuracy: 0.5702\n",
      "Epoch 13/50\n",
      "25716/25716 [==============================] - 2s 59us/sample - loss: 0.6812 - accuracy: 0.5713\n",
      "Epoch 14/50\n",
      "25716/25716 [==============================] - 1s 49us/sample - loss: 0.6816 - accuracy: 0.5730\n",
      "Epoch 15/50\n",
      "25716/25716 [==============================] - 1s 48us/sample - loss: 0.6813 - accuracy: 0.5728\n",
      "Epoch 16/50\n",
      "25716/25716 [==============================] - 2s 59us/sample - loss: 0.6811 - accuracy: 0.5720\n",
      "Epoch 17/50\n",
      "25716/25716 [==============================] - 1s 58us/sample - loss: 0.6807 - accuracy: 0.5719\n",
      "Epoch 18/50\n",
      "25716/25716 [==============================] - 1s 47us/sample - loss: 0.6807 - accuracy: 0.5731\n",
      "Epoch 19/50\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6806 - accuracy: 0.5727\n",
      "Epoch 20/50\n",
      "25716/25716 [==============================] - 1s 58us/sample - loss: 0.6808 - accuracy: 0.5716\n",
      "Epoch 21/50\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6804 - accuracy: 0.5742\n",
      "Epoch 22/50\n",
      "25716/25716 [==============================] - 1s 48us/sample - loss: 0.6805 - accuracy: 0.5744\n",
      "Epoch 23/50\n",
      "25716/25716 [==============================] - 1s 48us/sample - loss: 0.6804 - accuracy: 0.5745\n",
      "Epoch 24/50\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6802 - accuracy: 0.5723\n",
      "Epoch 25/50\n",
      "25716/25716 [==============================] - 2s 60us/sample - loss: 0.6803 - accuracy: 0.5726\n",
      "Epoch 26/50\n",
      "25716/25716 [==============================] - 1s 58us/sample - loss: 0.6800 - accuracy: 0.5738\n",
      "Epoch 27/50\n",
      "25716/25716 [==============================] - 2s 60us/sample - loss: 0.6799 - accuracy: 0.5742\n",
      "Epoch 28/50\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6799 - accuracy: 0.5730\n",
      "Epoch 29/50\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6797 - accuracy: 0.5733\n",
      "Epoch 30/50\n",
      "25716/25716 [==============================] - 1s 49us/sample - loss: 0.6799 - accuracy: 0.5749\n",
      "Epoch 31/50\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6797 - accuracy: 0.5752\n",
      "Epoch 32/50\n",
      "25716/25716 [==============================] - 2s 73us/sample - loss: 0.6798 - accuracy: 0.5754\n",
      "Epoch 33/50\n",
      "25716/25716 [==============================] - 2s 61us/sample - loss: 0.6795 - accuracy: 0.5750\n",
      "Epoch 34/50\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6793 - accuracy: 0.5740\n",
      "Epoch 35/50\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6794 - accuracy: 0.5750\n",
      "Epoch 36/50\n",
      "25716/25716 [==============================] - 1s 47us/sample - loss: 0.6795 - accuracy: 0.5741\n",
      "Epoch 37/50\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6793 - accuracy: 0.5761\n",
      "Epoch 38/50\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6794 - accuracy: 0.5742\n",
      "Epoch 39/50\n",
      "25716/25716 [==============================] - 1s 47us/sample - loss: 0.6793 - accuracy: 0.5750\n",
      "Epoch 40/50\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6791 - accuracy: 0.5764\n",
      "Epoch 41/50\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6789 - accuracy: 0.5766\n",
      "Epoch 42/50\n",
      "25716/25716 [==============================] - 2s 59us/sample - loss: 0.6789 - accuracy: 0.5773\n",
      "Epoch 43/50\n",
      "25716/25716 [==============================] - 1s 57us/sample - loss: 0.6790 - accuracy: 0.5771\n",
      "Epoch 44/50\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6787 - accuracy: 0.5766\n",
      "Epoch 45/50\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6790 - accuracy: 0.5759\n",
      "Epoch 46/50\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6788 - accuracy: 0.5748\n",
      "Epoch 47/50\n",
      "25716/25716 [==============================] - 2s 67us/sample - loss: 0.6786 - accuracy: 0.5770\n",
      "Epoch 48/50\n",
      "25716/25716 [==============================] - 1s 55us/sample - loss: 0.6785 - accuracy: 0.5747\n",
      "Epoch 49/50\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6788 - accuracy: 0.5745\n",
      "Epoch 50/50\n",
      "25716/25716 [==============================] - 1s 49us/sample - loss: 0.6783 - accuracy: 0.5768\n",
      "8573/1 - 0s - loss: 0.6881 - accuracy: 0.5580\n",
      "Loss: 0.6862750355635309, Accuracy: 0.5580310225486755\n"
     ]
    }
   ],
   "source": [
    "# Increase number of neurons to four times number of inputs\n",
    "hidden_nodes_layer1 = len(X_train_scaled[0])*4\n",
    "\n",
    "# The remained of the model remains the sameDefine\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "nn = tf.keras.models.Sequential()\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "fit_model = nn.fit(X_train_scaled, numpy.array(y_train), epochs=50)\n",
    "\n",
    "# Use the test dataset to evaluate this version of the model\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, numpy.array(y_test), verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy is 56%\n",
    "\n",
    "8573/1 - 0s - loss: 0.6881 - accuracy: 0.5580\n",
    "        \n",
    "Loss: 0.6862750355635309, Accuracy: 0.5580310225486755"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvment attempt 2 - Add second hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25716 samples\n",
      "Epoch 1/50\n",
      "25716/25716 [==============================] - 2s 71us/sample - loss: 0.6884 - accuracy: 0.5583\n",
      "Epoch 2/50\n",
      "25716/25716 [==============================] - 1s 47us/sample - loss: 0.6839 - accuracy: 0.5670\n",
      "Epoch 3/50\n",
      "25716/25716 [==============================] - 1s 47us/sample - loss: 0.6830 - accuracy: 0.5695\n",
      "Epoch 4/50\n",
      "25716/25716 [==============================] - 1s 49us/sample - loss: 0.6820 - accuracy: 0.5713\n",
      "Epoch 5/50\n",
      "25716/25716 [==============================] - 1s 48us/sample - loss: 0.6820 - accuracy: 0.5696\n",
      "Epoch 6/50\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6814 - accuracy: 0.5703\n",
      "Epoch 7/50\n",
      "25716/25716 [==============================] - 1s 48us/sample - loss: 0.6809 - accuracy: 0.5729\n",
      "Epoch 8/50\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6810 - accuracy: 0.5741\n",
      "Epoch 9/50\n",
      "25716/25716 [==============================] - 1s 57us/sample - loss: 0.6806 - accuracy: 0.5762\n",
      "Epoch 10/50\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6804 - accuracy: 0.5753\n",
      "Epoch 11/50\n",
      "25716/25716 [==============================] - 1s 49us/sample - loss: 0.6800 - accuracy: 0.5740\n",
      "Epoch 12/50\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6797 - accuracy: 0.5744\n",
      "Epoch 13/50\n",
      "25716/25716 [==============================] - 1s 49us/sample - loss: 0.6800 - accuracy: 0.5763\n",
      "Epoch 14/50\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6796 - accuracy: 0.5758\n",
      "Epoch 15/50\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6795 - accuracy: 0.5761\n",
      "Epoch 16/50\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6794 - accuracy: 0.5750\n",
      "Epoch 17/50\n",
      "25716/25716 [==============================] - 2s 83us/sample - loss: 0.6793 - accuracy: 0.5765\n",
      "Epoch 18/50\n",
      "25716/25716 [==============================] - 2s 63us/sample - loss: 0.6790 - accuracy: 0.5772\n",
      "Epoch 19/50\n",
      "25716/25716 [==============================] - 2s 62us/sample - loss: 0.6788 - accuracy: 0.5768\n",
      "Epoch 20/50\n",
      "25716/25716 [==============================] - 1s 55us/sample - loss: 0.6783 - accuracy: 0.5777\n",
      "Epoch 21/50\n",
      "25716/25716 [==============================] - 1s 55us/sample - loss: 0.6785 - accuracy: 0.5768\n",
      "Epoch 22/50\n",
      "25716/25716 [==============================] - 2s 59us/sample - loss: 0.6786 - accuracy: 0.5777\n",
      "Epoch 23/50\n",
      "25716/25716 [==============================] - 1s 55us/sample - loss: 0.6783 - accuracy: 0.5763\n",
      "Epoch 24/50\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6780 - accuracy: 0.5776\n",
      "Epoch 25/50\n",
      "25716/25716 [==============================] - 1s 56us/sample - loss: 0.6782 - accuracy: 0.5773\n",
      "Epoch 26/50\n",
      "25716/25716 [==============================] - 1s 55us/sample - loss: 0.6778 - accuracy: 0.5791\n",
      "Epoch 27/50\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6777 - accuracy: 0.5792\n",
      "Epoch 28/50\n",
      "25716/25716 [==============================] - 1s 55us/sample - loss: 0.6774 - accuracy: 0.5785\n",
      "Epoch 29/50\n",
      "25716/25716 [==============================] - 2s 60us/sample - loss: 0.6776 - accuracy: 0.5787\n",
      "Epoch 30/50\n",
      "25716/25716 [==============================] - 2s 63us/sample - loss: 0.6775 - accuracy: 0.5780\n",
      "Epoch 31/50\n",
      "25716/25716 [==============================] - 2s 60us/sample - loss: 0.6772 - accuracy: 0.5799\n",
      "Epoch 32/50\n",
      "25716/25716 [==============================] - 2s 59us/sample - loss: 0.6772 - accuracy: 0.5792\n",
      "Epoch 33/50\n",
      "25716/25716 [==============================] - 2s 59us/sample - loss: 0.6773 - accuracy: 0.5799\n",
      "Epoch 34/50\n",
      "25716/25716 [==============================] - 1s 57us/sample - loss: 0.6773 - accuracy: 0.5786\n",
      "Epoch 35/50\n",
      "25716/25716 [==============================] - 2s 58us/sample - loss: 0.6768 - accuracy: 0.5802\n",
      "Epoch 36/50\n",
      "25716/25716 [==============================] - 2s 61us/sample - loss: 0.6766 - accuracy: 0.5809\n",
      "Epoch 37/50\n",
      "25716/25716 [==============================] - 2s 66us/sample - loss: 0.6765 - accuracy: 0.5791\n",
      "Epoch 38/50\n",
      "25716/25716 [==============================] - 2s 70us/sample - loss: 0.6764 - accuracy: 0.5788\n",
      "Epoch 39/50\n",
      "25716/25716 [==============================] - 2s 65us/sample - loss: 0.6763 - accuracy: 0.5800\n",
      "Epoch 40/50\n",
      "25716/25716 [==============================] - 2s 60us/sample - loss: 0.6761 - accuracy: 0.5802\n",
      "Epoch 41/50\n",
      "25716/25716 [==============================] - 2s 59us/sample - loss: 0.6764 - accuracy: 0.5791\n",
      "Epoch 42/50\n",
      "25716/25716 [==============================] - 2s 59us/sample - loss: 0.6768 - accuracy: 0.5802\n",
      "Epoch 43/50\n",
      "25716/25716 [==============================] - 2s 65us/sample - loss: 0.6760 - accuracy: 0.5802\n",
      "Epoch 44/50\n",
      "25716/25716 [==============================] - 2s 64us/sample - loss: 0.6762 - accuracy: 0.5802\n",
      "Epoch 45/50\n",
      "25716/25716 [==============================] - 2s 65us/sample - loss: 0.6755 - accuracy: 0.5811\n",
      "Epoch 46/50\n",
      "25716/25716 [==============================] - 2s 65us/sample - loss: 0.6759 - accuracy: 0.5793\n",
      "Epoch 47/50\n",
      "25716/25716 [==============================] - 2s 62us/sample - loss: 0.6753 - accuracy: 0.5811\n",
      "Epoch 48/50\n",
      "25716/25716 [==============================] - 1s 57us/sample - loss: 0.6755 - accuracy: 0.5810\n",
      "Epoch 49/50\n",
      "25716/25716 [==============================] - 2s 63us/sample - loss: 0.6751 - accuracy: 0.5814\n",
      "Epoch 50/50\n",
      "25716/25716 [==============================] - 1s 57us/sample - loss: 0.6752 - accuracy: 0.5807\n",
      "8573/1 - 0s - loss: 0.6883 - accuracy: 0.5618\n",
      "Loss: 0.6913094726504877, Accuracy: 0.5617637038230896\n"
     ]
    }
   ],
   "source": [
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = len(X_train_scaled[0])*3\n",
    "nn = tf.keras.models.Sequential()\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Adding a second hidden layer, ration of one for number of neurons to input layer number of neurons \n",
    "hidden_nodes_layer2 = len(X_train_scaled[0])\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "fit_model = nn.fit(X_train_scaled, numpy.array(y_train), epochs=50)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,numpy.array(y_test),verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy 56%\n",
    "\n",
    "8573/1 - 0s - loss: 0.6883 - accuracy: 0.5618\n",
    "        \n",
    "Loss: 0.6913094726504877, Accuracy: 0.5617637038230896"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvment attempt 3 - Double the number of epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25716 samples\n",
      "Epoch 1/100\n",
      "25716/25716 [==============================] - 2s 71us/sample - loss: 0.6899 - accuracy: 0.5554\n",
      "Epoch 2/100\n",
      "25716/25716 [==============================] - 1s 48us/sample - loss: 0.6857 - accuracy: 0.5633\n",
      "Epoch 3/100\n",
      "25716/25716 [==============================] - 1s 47us/sample - loss: 0.6834 - accuracy: 0.5695\n",
      "Epoch 4/100\n",
      "25716/25716 [==============================] - 1s 48us/sample - loss: 0.6824 - accuracy: 0.5714\n",
      "Epoch 5/100\n",
      "25716/25716 [==============================] - 1s 49us/sample - loss: 0.6817 - accuracy: 0.5710\n",
      "Epoch 6/100\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6816 - accuracy: 0.5729\n",
      "Epoch 7/100\n",
      "25716/25716 [==============================] - 1s 47us/sample - loss: 0.6812 - accuracy: 0.5725\n",
      "Epoch 8/100\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6810 - accuracy: 0.5719\n",
      "Epoch 9/100\n",
      "25716/25716 [==============================] - 1s 55us/sample - loss: 0.6806 - accuracy: 0.5731\n",
      "Epoch 10/100\n",
      "25716/25716 [==============================] - 1s 57us/sample - loss: 0.6802 - accuracy: 0.5732\n",
      "Epoch 11/100\n",
      "25716/25716 [==============================] - 2s 69us/sample - loss: 0.6802 - accuracy: 0.5742\n",
      "Epoch 12/100\n",
      "25716/25716 [==============================] - 1s 55us/sample - loss: 0.6799 - accuracy: 0.5761\n",
      "Epoch 13/100\n",
      "25716/25716 [==============================] - 1s 55us/sample - loss: 0.6797 - accuracy: 0.5749\n",
      "Epoch 14/100\n",
      "25716/25716 [==============================] - 2s 67us/sample - loss: 0.6793 - accuracy: 0.5759\n",
      "Epoch 15/100\n",
      "25716/25716 [==============================] - 1s 56us/sample - loss: 0.6796 - accuracy: 0.5762\n",
      "Epoch 16/100\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6791 - accuracy: 0.5761\n",
      "Epoch 17/100\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6787 - accuracy: 0.5759\n",
      "Epoch 18/100\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6790 - accuracy: 0.5766\n",
      "Epoch 19/100\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6787 - accuracy: 0.5773\n",
      "Epoch 20/100\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6786 - accuracy: 0.5779\n",
      "Epoch 21/100\n",
      "25716/25716 [==============================] - 1s 49us/sample - loss: 0.6787 - accuracy: 0.5768\n",
      "Epoch 22/100\n",
      "25716/25716 [==============================] - 1s 49us/sample - loss: 0.6782 - accuracy: 0.5774\n",
      "Epoch 23/100\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6782 - accuracy: 0.5775\n",
      "Epoch 24/100\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6782 - accuracy: 0.5778\n",
      "Epoch 25/100\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6782 - accuracy: 0.5796\n",
      "Epoch 26/100\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6777 - accuracy: 0.5786\n",
      "Epoch 27/100\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6777 - accuracy: 0.5785\n",
      "Epoch 28/100\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6776 - accuracy: 0.5792\n",
      "Epoch 29/100\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6775 - accuracy: 0.5788\n",
      "Epoch 30/100\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6774 - accuracy: 0.5794\n",
      "Epoch 31/100\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6768 - accuracy: 0.5802\n",
      "Epoch 32/100\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6770 - accuracy: 0.5797\n",
      "Epoch 33/100\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6769 - accuracy: 0.5793\n",
      "Epoch 34/100\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6766 - accuracy: 0.5798\n",
      "Epoch 35/100\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6764 - accuracy: 0.5793\n",
      "Epoch 36/100\n",
      "25716/25716 [==============================] - 1s 49us/sample - loss: 0.6765 - accuracy: 0.5798\n",
      "Epoch 37/100\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6762 - accuracy: 0.5792\n",
      "Epoch 38/100\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6763 - accuracy: 0.5803\n",
      "Epoch 39/100\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6761 - accuracy: 0.5804\n",
      "Epoch 40/100\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6761 - accuracy: 0.5803\n",
      "Epoch 41/100\n",
      "25716/25716 [==============================] - 1s 55us/sample - loss: 0.6756 - accuracy: 0.5804\n",
      "Epoch 42/100\n",
      "25716/25716 [==============================] - 2s 59us/sample - loss: 0.6755 - accuracy: 0.5814\n",
      "Epoch 43/100\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6754 - accuracy: 0.5803\n",
      "Epoch 44/100\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6755 - accuracy: 0.5801\n",
      "Epoch 45/100\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6753 - accuracy: 0.5800\n",
      "Epoch 46/100\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6754 - accuracy: 0.5805\n",
      "Epoch 47/100\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6753 - accuracy: 0.5803\n",
      "Epoch 48/100\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6755 - accuracy: 0.5813\n",
      "Epoch 49/100\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6751 - accuracy: 0.5815\n",
      "Epoch 50/100\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6752 - accuracy: 0.5801\n",
      "Epoch 51/100\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6748 - accuracy: 0.5801\n",
      "Epoch 52/100\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6748 - accuracy: 0.5811\n",
      "Epoch 53/100\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6745 - accuracy: 0.5811\n",
      "Epoch 54/100\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6748 - accuracy: 0.5814\n",
      "Epoch 55/100\n",
      "25716/25716 [==============================] - 1s 56us/sample - loss: 0.6744 - accuracy: 0.5812\n",
      "Epoch 56/100\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6747 - accuracy: 0.5807\n",
      "Epoch 57/100\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6746 - accuracy: 0.5814\n",
      "Epoch 58/100\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6746 - accuracy: 0.5815\n",
      "Epoch 59/100\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6743 - accuracy: 0.5823\n",
      "Epoch 60/100\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6742 - accuracy: 0.5808\n",
      "Epoch 61/100\n",
      "25716/25716 [==============================] - 1s 57us/sample - loss: 0.6741 - accuracy: 0.5807\n",
      "Epoch 62/100\n",
      "25716/25716 [==============================] - 2s 59us/sample - loss: 0.6741 - accuracy: 0.5808\n",
      "Epoch 63/100\n",
      "25716/25716 [==============================] - 1s 56us/sample - loss: 0.6744 - accuracy: 0.5806\n",
      "Epoch 64/100\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6736 - accuracy: 0.5808\n",
      "Epoch 65/100\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6754 - accuracy: 0.5816\n",
      "Epoch 66/100\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6740 - accuracy: 0.5814\n",
      "Epoch 67/100\n",
      "25716/25716 [==============================] - 1s 55us/sample - loss: 0.6732 - accuracy: 0.5823\n",
      "Epoch 68/100\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6737 - accuracy: 0.5826\n",
      "Epoch 69/100\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6738 - accuracy: 0.5819\n",
      "Epoch 70/100\n",
      "25716/25716 [==============================] - 1s 58us/sample - loss: 0.6735 - accuracy: 0.5819\n",
      "Epoch 71/100\n",
      "25716/25716 [==============================] - 2s 63us/sample - loss: 0.6734 - accuracy: 0.5817\n",
      "Epoch 72/100\n",
      "25716/25716 [==============================] - 1s 56us/sample - loss: 0.6738 - accuracy: 0.5812\n",
      "Epoch 73/100\n",
      "25716/25716 [==============================] - 2s 72us/sample - loss: 0.6735 - accuracy: 0.5818\n",
      "Epoch 74/100\n",
      "25716/25716 [==============================] - 2s 60us/sample - loss: 0.6733 - accuracy: 0.5818\n",
      "Epoch 75/100\n",
      "25716/25716 [==============================] - 2s 59us/sample - loss: 0.6731 - accuracy: 0.5824\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6732 - accuracy: 0.5828\n",
      "Epoch 77/100\n",
      "25716/25716 [==============================] - 1s 57us/sample - loss: 0.6732 - accuracy: 0.5815\n",
      "Epoch 78/100\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6733 - accuracy: 0.5823\n",
      "Epoch 79/100\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6733 - accuracy: 0.5820\n",
      "Epoch 80/100\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6733 - accuracy: 0.5828\n",
      "Epoch 81/100\n",
      "25716/25716 [==============================] - 1s 56us/sample - loss: 0.6729 - accuracy: 0.5827\n",
      "Epoch 82/100\n",
      "25716/25716 [==============================] - 1s 55us/sample - loss: 0.6733 - accuracy: 0.5826\n",
      "Epoch 83/100\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6727 - accuracy: 0.5829\n",
      "Epoch 84/100\n",
      "25716/25716 [==============================] - 2s 69us/sample - loss: 0.6728 - accuracy: 0.5826\n",
      "Epoch 85/100\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6729 - accuracy: 0.5825\n",
      "Epoch 86/100\n",
      "25716/25716 [==============================] - 1s 55us/sample - loss: 0.6729 - accuracy: 0.5818\n",
      "Epoch 87/100\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6728 - accuracy: 0.5822\n",
      "Epoch 88/100\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6727 - accuracy: 0.5816\n",
      "Epoch 89/100\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6745 - accuracy: 0.5817\n",
      "Epoch 90/100\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6736 - accuracy: 0.5821\n",
      "Epoch 91/100\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6729 - accuracy: 0.5819\n",
      "Epoch 92/100\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6724 - accuracy: 0.5822\n",
      "Epoch 93/100\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6723 - accuracy: 0.5819\n",
      "Epoch 94/100\n",
      "25716/25716 [==============================] - 1s 55us/sample - loss: 0.6729 - accuracy: 0.5822\n",
      "Epoch 95/100\n",
      "25716/25716 [==============================] - 1s 55us/sample - loss: 0.6727 - accuracy: 0.5831\n",
      "Epoch 96/100\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6730 - accuracy: 0.5824\n",
      "Epoch 97/100\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6726 - accuracy: 0.5822\n",
      "Epoch 98/100\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6723 - accuracy: 0.5825\n",
      "Epoch 99/100\n",
      "25716/25716 [==============================] - 1s 56us/sample - loss: 0.6724 - accuracy: 0.5831\n",
      "Epoch 100/100\n",
      "25716/25716 [==============================] - 2s 63us/sample - loss: 0.6722 - accuracy: 0.5821\n",
      "8573/1 - 0s - loss: 0.6988 - accuracy: 0.5618\n",
      "Loss: 0.6978942001420754, Accuracy: 0.5617637038230896\n"
     ]
    }
   ],
   "source": [
    "number_input_features = len(X_train_scaled[0])\n",
    "nn = tf.keras.models.Sequential()\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "hidden_nodes_layer1 = len(X_train_scaled[0])*4\n",
    "hidden_nodes_layer2 = len(X_train_scaled[0])\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "# Double the number of epochs\n",
    "fit_model = nn.fit(X_train_scaled, numpy.array(y_train), epochs=100)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, numpy.array(y_test),verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy still 56%\n",
    "\n",
    "8573/1 - 0s - loss: 0.6926 - accuracy: 0.5612\n",
    "\n",
    "Loss: 0.6982309062242035, Accuracy: 0.5611804723739624"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvment attempt 3 - Double again the number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25716 samples\n",
      "Epoch 1/200\n",
      "25716/25716 [==============================] - 2s 77us/sample - loss: 0.6899 - accuracy: 0.5562\n",
      "Epoch 2/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6850 - accuracy: 0.5677\n",
      "Epoch 3/200\n",
      "25716/25716 [==============================] - 1s 49us/sample - loss: 0.6831 - accuracy: 0.5681\n",
      "Epoch 4/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6823 - accuracy: 0.5690\n",
      "Epoch 5/200\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6814 - accuracy: 0.5716\n",
      "Epoch 6/200\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6815 - accuracy: 0.5709\n",
      "Epoch 7/200\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6813 - accuracy: 0.5724\n",
      "Epoch 8/200\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6811 - accuracy: 0.5724\n",
      "Epoch 9/200\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6807 - accuracy: 0.5732\n",
      "Epoch 10/200\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6809 - accuracy: 0.5736\n",
      "Epoch 11/200\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6804 - accuracy: 0.5748\n",
      "Epoch 12/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6803 - accuracy: 0.5764\n",
      "Epoch 13/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6800 - accuracy: 0.5770\n",
      "Epoch 14/200\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6797 - accuracy: 0.5750\n",
      "Epoch 15/200\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6798 - accuracy: 0.5748\n",
      "Epoch 16/200\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6797 - accuracy: 0.5771\n",
      "Epoch 17/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6793 - accuracy: 0.5777\n",
      "Epoch 18/200\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6792 - accuracy: 0.5769\n",
      "Epoch 19/200\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6791 - accuracy: 0.5772\n",
      "Epoch 20/200\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6789 - accuracy: 0.5779\n",
      "Epoch 21/200\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6786 - accuracy: 0.5776\n",
      "Epoch 22/200\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6785 - accuracy: 0.5775\n",
      "Epoch 23/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6784 - accuracy: 0.5783\n",
      "Epoch 24/200\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6783 - accuracy: 0.5796\n",
      "Epoch 25/200\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6781 - accuracy: 0.5798\n",
      "Epoch 26/200\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6779 - accuracy: 0.5787\n",
      "Epoch 27/200\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6777 - accuracy: 0.5780\n",
      "Epoch 28/200\n",
      "25716/25716 [==============================] - 1s 55us/sample - loss: 0.6777 - accuracy: 0.5786\n",
      "Epoch 29/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6773 - accuracy: 0.5801\n",
      "Epoch 30/200\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6772 - accuracy: 0.5792\n",
      "Epoch 31/200\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6772 - accuracy: 0.5788\n",
      "Epoch 32/200\n",
      "25716/25716 [==============================] - 1s 55us/sample - loss: 0.6773 - accuracy: 0.5798\n",
      "Epoch 33/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6769 - accuracy: 0.5789\n",
      "Epoch 34/200\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6768 - accuracy: 0.5793\n",
      "Epoch 35/200\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6767 - accuracy: 0.5798\n",
      "Epoch 36/200\n",
      "25716/25716 [==============================] - 1s 56us/sample - loss: 0.6765 - accuracy: 0.5801\n",
      "Epoch 37/200\n",
      "25716/25716 [==============================] - 2s 59us/sample - loss: 0.6764 - accuracy: 0.5793\n",
      "Epoch 38/200\n",
      "25716/25716 [==============================] - 2s 68us/sample - loss: 0.6762 - accuracy: 0.5798\n",
      "Epoch 39/200\n",
      "25716/25716 [==============================] - 2s 69us/sample - loss: 0.6762 - accuracy: 0.5798\n",
      "Epoch 40/200\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6760 - accuracy: 0.5794\n",
      "Epoch 41/200\n",
      "25716/25716 [==============================] - 1s 55us/sample - loss: 0.6761 - accuracy: 0.5801\n",
      "Epoch 42/200\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6759 - accuracy: 0.5808\n",
      "Epoch 43/200\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6757 - accuracy: 0.5806\n",
      "Epoch 44/200\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6758 - accuracy: 0.5800\n",
      "Epoch 45/200\n",
      "25716/25716 [==============================] - 2s 90us/sample - loss: 0.6755 - accuracy: 0.5806\n",
      "Epoch 46/200\n",
      "25716/25716 [==============================] - 2s 84us/sample - loss: 0.6751 - accuracy: 0.5809\n",
      "Epoch 47/200\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6751 - accuracy: 0.5813\n",
      "Epoch 48/200\n",
      "25716/25716 [==============================] - 2s 64us/sample - loss: 0.6751 - accuracy: 0.5812\n",
      "Epoch 49/200\n",
      "25716/25716 [==============================] - 1s 56us/sample - loss: 0.6750 - accuracy: 0.5810\n",
      "Epoch 50/200\n",
      "25716/25716 [==============================] - 1s 55us/sample - loss: 0.6747 - accuracy: 0.5812\n",
      "Epoch 51/200\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6748 - accuracy: 0.5803\n",
      "Epoch 52/200\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6753 - accuracy: 0.5816\n",
      "Epoch 53/200\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6749 - accuracy: 0.5810\n",
      "Epoch 54/200\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6743 - accuracy: 0.5815\n",
      "Epoch 55/200\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6746 - accuracy: 0.5805\n",
      "Epoch 56/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6743 - accuracy: 0.5815\n",
      "Epoch 57/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6741 - accuracy: 0.5814\n",
      "Epoch 58/200\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6743 - accuracy: 0.5805\n",
      "Epoch 59/200\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6741 - accuracy: 0.5812\n",
      "Epoch 60/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6741 - accuracy: 0.5804\n",
      "Epoch 61/200\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6739 - accuracy: 0.5823\n",
      "Epoch 62/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6739 - accuracy: 0.5811\n",
      "Epoch 63/200\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6738 - accuracy: 0.5817\n",
      "Epoch 64/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6734 - accuracy: 0.5816\n",
      "Epoch 65/200\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6739 - accuracy: 0.5824\n",
      "Epoch 66/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6732 - accuracy: 0.5815\n",
      "Epoch 67/200\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6738 - accuracy: 0.5813\n",
      "Epoch 68/200\n",
      "25716/25716 [==============================] - 2s 59us/sample - loss: 0.6738 - accuracy: 0.5821\n",
      "Epoch 69/200\n",
      "25716/25716 [==============================] - 1s 57us/sample - loss: 0.6735 - accuracy: 0.5822\n",
      "Epoch 70/200\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6732 - accuracy: 0.5824\n",
      "Epoch 71/200\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6731 - accuracy: 0.5824\n",
      "Epoch 72/200\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6730 - accuracy: 0.5821\n",
      "Epoch 73/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6735 - accuracy: 0.5819\n",
      "Epoch 74/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6740 - accuracy: 0.5814\n",
      "Epoch 75/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6731 - accuracy: 0.5823\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6731 - accuracy: 0.5826\n",
      "Epoch 77/200\n",
      "25716/25716 [==============================] - 2s 63us/sample - loss: 0.6725 - accuracy: 0.5829\n",
      "Epoch 78/200\n",
      "25716/25716 [==============================] - 1s 57us/sample - loss: 0.6729 - accuracy: 0.5829\n",
      "Epoch 79/200\n",
      "25716/25716 [==============================] - 2s 63us/sample - loss: 0.6726 - accuracy: 0.5824\n",
      "Epoch 80/200\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6729 - accuracy: 0.5826\n",
      "Epoch 81/200\n",
      "25716/25716 [==============================] - 2s 60us/sample - loss: 0.6725 - accuracy: 0.5833\n",
      "Epoch 82/200\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6726 - accuracy: 0.5826\n",
      "Epoch 83/200\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6728 - accuracy: 0.5826\n",
      "Epoch 84/200\n",
      "25716/25716 [==============================] - 2s 61us/sample - loss: 0.6730 - accuracy: 0.5827\n",
      "Epoch 85/200\n",
      "25716/25716 [==============================] - 1s 55us/sample - loss: 0.6726 - accuracy: 0.5831\n",
      "Epoch 86/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6727 - accuracy: 0.5828\n",
      "Epoch 87/200\n",
      "25716/25716 [==============================] - 1s 57us/sample - loss: 0.6724 - accuracy: 0.5834\n",
      "Epoch 88/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6726 - accuracy: 0.5831\n",
      "Epoch 89/200\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6725 - accuracy: 0.5833\n",
      "Epoch 90/200\n",
      "25716/25716 [==============================] - 1s 55us/sample - loss: 0.6737 - accuracy: 0.5827\n",
      "Epoch 91/200\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6749 - accuracy: 0.5824\n",
      "Epoch 92/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6726 - accuracy: 0.5826\n",
      "Epoch 93/200\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6763 - accuracy: 0.5835\n",
      "Epoch 94/200\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6715 - accuracy: 0.5829\n",
      "Epoch 95/200\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6720 - accuracy: 0.5829\n",
      "Epoch 96/200\n",
      "25716/25716 [==============================] - 2s 60us/sample - loss: 0.6720 - accuracy: 0.5831\n",
      "Epoch 97/200\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6719 - accuracy: 0.5830\n",
      "Epoch 98/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6719 - accuracy: 0.5828\n",
      "Epoch 99/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6718 - accuracy: 0.5829\n",
      "Epoch 100/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6721 - accuracy: 0.5822\n",
      "Epoch 101/200\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6717 - accuracy: 0.5833\n",
      "Epoch 102/200\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6723 - accuracy: 0.5827\n",
      "Epoch 103/200\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6718 - accuracy: 0.5829\n",
      "Epoch 104/200\n",
      "25716/25716 [==============================] - 2s 59us/sample - loss: 0.6719 - accuracy: 0.5833\n",
      "Epoch 105/200\n",
      "25716/25716 [==============================] - 2s 63us/sample - loss: 0.6716 - accuracy: 0.5834\n",
      "Epoch 106/200\n",
      "25716/25716 [==============================] - 1s 58us/sample - loss: 0.6723 - accuracy: 0.5829\n",
      "Epoch 107/200\n",
      "25716/25716 [==============================] - 1s 55us/sample - loss: 0.6719 - accuracy: 0.5827\n",
      "Epoch 108/200\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6739 - accuracy: 0.5836\n",
      "Epoch 109/200\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6741 - accuracy: 0.5836\n",
      "Epoch 110/200\n",
      "25716/25716 [==============================] - 2s 60us/sample - loss: 0.6721 - accuracy: 0.5835\n",
      "Epoch 111/200\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6764 - accuracy: 0.5833\n",
      "Epoch 112/200\n",
      "25716/25716 [==============================] - 1s 55us/sample - loss: 0.6742 - accuracy: 0.5834\n",
      "Epoch 113/200\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6710 - accuracy: 0.5842\n",
      "Epoch 114/200\n",
      "25716/25716 [==============================] - 2s 61us/sample - loss: 0.6716 - accuracy: 0.5834\n",
      "Epoch 115/200\n",
      "25716/25716 [==============================] - 2s 58us/sample - loss: 0.6711 - accuracy: 0.5829\n",
      "Epoch 116/200\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6714 - accuracy: 0.5833\n",
      "Epoch 117/200\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6711 - accuracy: 0.5829\n",
      "Epoch 118/200\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6712 - accuracy: 0.5833\n",
      "Epoch 119/200\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6714 - accuracy: 0.5835\n",
      "Epoch 120/200\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6718 - accuracy: 0.5833\n",
      "Epoch 121/200\n",
      "25716/25716 [==============================] - 2s 64us/sample - loss: 0.6717 - accuracy: 0.5821\n",
      "Epoch 122/200\n",
      "25716/25716 [==============================] - 2s 63us/sample - loss: 0.6711 - accuracy: 0.5830\n",
      "Epoch 123/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6712 - accuracy: 0.5843\n",
      "Epoch 124/200\n",
      "25716/25716 [==============================] - 1s 57us/sample - loss: 0.6710 - accuracy: 0.5834\n",
      "Epoch 125/200\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6707 - accuracy: 0.5833\n",
      "Epoch 126/200\n",
      "25716/25716 [==============================] - 1s 49us/sample - loss: 0.6733 - accuracy: 0.5836\n",
      "Epoch 127/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6713 - accuracy: 0.5839\n",
      "Epoch 128/200\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6708 - accuracy: 0.5831\n",
      "Epoch 129/200\n",
      "25716/25716 [==============================] - 1s 56us/sample - loss: 0.6708 - accuracy: 0.5837\n",
      "Epoch 130/200\n",
      "25716/25716 [==============================] - 2s 66us/sample - loss: 0.6713 - accuracy: 0.5842\n",
      "Epoch 131/200\n",
      "25716/25716 [==============================] - 2s 61us/sample - loss: 0.6708 - accuracy: 0.5838\n",
      "Epoch 132/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6721 - accuracy: 0.5838\n",
      "Epoch 133/200\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6703 - accuracy: 0.5841\n",
      "Epoch 134/200\n",
      "25716/25716 [==============================] - 2s 65us/sample - loss: 0.6707 - accuracy: 0.5845\n",
      "Epoch 135/200\n",
      "25716/25716 [==============================] - 2s 62us/sample - loss: 0.6714 - accuracy: 0.5828\n",
      "Epoch 136/200\n",
      "25716/25716 [==============================] - 1s 58us/sample - loss: 0.6705 - accuracy: 0.5836\n",
      "Epoch 137/200\n",
      "25716/25716 [==============================] - 2s 59us/sample - loss: 0.6701 - accuracy: 0.5831\n",
      "Epoch 138/200\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6705 - accuracy: 0.5837\n",
      "Epoch 139/200\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6745 - accuracy: 0.5828\n",
      "Epoch 140/200\n",
      "25716/25716 [==============================] - 2s 59us/sample - loss: 0.6711 - accuracy: 0.5840\n",
      "Epoch 141/200\n",
      "25716/25716 [==============================] - 1s 55us/sample - loss: 0.6704 - accuracy: 0.5834\n",
      "Epoch 142/200\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6710 - accuracy: 0.5843\n",
      "Epoch 143/200\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6705 - accuracy: 0.5838\n",
      "Epoch 144/200\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6702 - accuracy: 0.5835\n",
      "Epoch 145/200\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6735 - accuracy: 0.5835\n",
      "Epoch 146/200\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6708 - accuracy: 0.5839\n",
      "Epoch 147/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6706 - accuracy: 0.5840\n",
      "Epoch 148/200\n",
      "25716/25716 [==============================] - 2s 59us/sample - loss: 0.6702 - accuracy: 0.5841\n",
      "Epoch 149/200\n",
      "25716/25716 [==============================] - 2s 61us/sample - loss: 0.6699 - accuracy: 0.5832\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6704 - accuracy: 0.5841\n",
      "Epoch 151/200\n",
      "25716/25716 [==============================] - 1s 49us/sample - loss: 0.6705 - accuracy: 0.5838\n",
      "Epoch 152/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6707 - accuracy: 0.5838\n",
      "Epoch 153/200\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6707 - accuracy: 0.5837\n",
      "Epoch 154/200\n",
      "25716/25716 [==============================] - 1s 55us/sample - loss: 0.6728 - accuracy: 0.5840\n",
      "Epoch 155/200\n",
      "25716/25716 [==============================] - 1s 49us/sample - loss: 0.6700 - accuracy: 0.5838\n",
      "Epoch 156/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6701 - accuracy: 0.5840\n",
      "Epoch 157/200\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6704 - accuracy: 0.5836\n",
      "Epoch 158/200\n",
      "25716/25716 [==============================] - 2s 68us/sample - loss: 0.6703 - accuracy: 0.5844\n",
      "Epoch 159/200\n",
      "25716/25716 [==============================] - 1s 57us/sample - loss: 0.6701 - accuracy: 0.5843\n",
      "Epoch 160/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6698 - accuracy: 0.5845\n",
      "Epoch 161/200\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6923 - accuracy: 0.5842\n",
      "Epoch 162/200\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6811 - accuracy: 0.5838\n",
      "Epoch 163/200\n",
      "25716/25716 [==============================] - 2s 66us/sample - loss: 0.6700 - accuracy: 0.5839\n",
      "Epoch 164/200\n",
      "25716/25716 [==============================] - 2s 61us/sample - loss: 0.6693 - accuracy: 0.5848\n",
      "Epoch 165/200\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6700 - accuracy: 0.5837\n",
      "Epoch 166/200\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6696 - accuracy: 0.5840\n",
      "Epoch 167/200\n",
      "25716/25716 [==============================] - 1s 56us/sample - loss: 0.6695 - accuracy: 0.5844\n",
      "Epoch 168/200\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6696 - accuracy: 0.5841\n",
      "Epoch 169/200\n",
      "25716/25716 [==============================] - 1s 49us/sample - loss: 0.6698 - accuracy: 0.5843\n",
      "Epoch 170/200\n",
      "25716/25716 [==============================] - 2s 61us/sample - loss: 0.6699 - accuracy: 0.5840\n",
      "Epoch 171/200\n",
      "25716/25716 [==============================] - 2s 61us/sample - loss: 0.6706 - accuracy: 0.5835\n",
      "Epoch 172/200\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6701 - accuracy: 0.5841\n",
      "Epoch 173/200\n",
      "25716/25716 [==============================] - 2s 60us/sample - loss: 0.6695 - accuracy: 0.5836\n",
      "Epoch 174/200\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6692 - accuracy: 0.5841\n",
      "Epoch 175/200\n",
      "25716/25716 [==============================] - 2s 59us/sample - loss: 0.6701 - accuracy: 0.5848\n",
      "Epoch 176/200\n",
      "25716/25716 [==============================] - 2s 60us/sample - loss: 0.6701 - accuracy: 0.5843\n",
      "Epoch 177/200\n",
      "25716/25716 [==============================] - 1s 56us/sample - loss: 0.6707 - accuracy: 0.5842\n",
      "Epoch 178/200\n",
      "25716/25716 [==============================] - 2s 73us/sample - loss: 0.6704 - accuracy: 0.5842\n",
      "Epoch 179/200\n",
      "25716/25716 [==============================] - 2s 93us/sample - loss: 0.6694 - accuracy: 0.5844\n",
      "Epoch 180/200\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6698 - accuracy: 0.5845\n",
      "Epoch 181/200\n",
      "25716/25716 [==============================] - 2s 61us/sample - loss: 0.6693 - accuracy: 0.5847\n",
      "Epoch 182/200\n",
      "25716/25716 [==============================] - 2s 81us/sample - loss: 0.6709 - accuracy: 0.5835\n",
      "Epoch 183/200\n",
      "25716/25716 [==============================] - 2s 81us/sample - loss: 0.6696 - accuracy: 0.5847\n",
      "Epoch 184/200\n",
      "25716/25716 [==============================] - 2s 79us/sample - loss: 0.6692 - accuracy: 0.5843\n",
      "Epoch 185/200\n",
      "25716/25716 [==============================] - 2s 81us/sample - loss: 0.6693 - accuracy: 0.5847\n",
      "Epoch 186/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6697 - accuracy: 0.5843\n",
      "Epoch 187/200\n",
      "25716/25716 [==============================] - 1s 54us/sample - loss: 0.6887 - accuracy: 0.5843\n",
      "Epoch 188/200\n",
      "25716/25716 [==============================] - 1s 51us/sample - loss: 0.6726 - accuracy: 0.5845\n",
      "Epoch 189/200\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6691 - accuracy: 0.5852\n",
      "Epoch 190/200\n",
      "25716/25716 [==============================] - 1s 53us/sample - loss: 0.6690 - accuracy: 0.5846\n",
      "Epoch 191/200\n",
      "25716/25716 [==============================] - 2s 64us/sample - loss: 0.6694 - accuracy: 0.5842\n",
      "Epoch 192/200\n",
      "25716/25716 [==============================] - 2s 59us/sample - loss: 0.6692 - accuracy: 0.5844\n",
      "Epoch 193/200\n",
      "25716/25716 [==============================] - 1s 58us/sample - loss: 0.6695 - accuracy: 0.5847\n",
      "Epoch 194/200\n",
      "25716/25716 [==============================] - 1s 50us/sample - loss: 0.6694 - accuracy: 0.5846\n",
      "Epoch 195/200\n",
      "25716/25716 [==============================] - 1s 56us/sample - loss: 0.6695 - accuracy: 0.5845\n",
      "Epoch 196/200\n",
      "25716/25716 [==============================] - 1s 58us/sample - loss: 0.6689 - accuracy: 0.5842\n",
      "Epoch 197/200\n",
      "25716/25716 [==============================] - 1s 55us/sample - loss: 0.6690 - accuracy: 0.5847\n",
      "Epoch 198/200\n",
      "25716/25716 [==============================] - 2s 61us/sample - loss: 0.6693 - accuracy: 0.5845\n",
      "Epoch 199/200\n",
      "25716/25716 [==============================] - 1s 52us/sample - loss: 0.6689 - accuracy: 0.5844\n",
      "Epoch 200/200\n",
      "25716/25716 [==============================] - 1s 58us/sample - loss: 0.6691 - accuracy: 0.5850\n",
      "8573/1 - 0s - loss: 0.7088 - accuracy: 0.5598\n",
      "Loss: 0.7132977329835054, Accuracy: 0.5597807168960571\n"
     ]
    }
   ],
   "source": [
    "number_input_features = len(X_train_scaled[0])\n",
    "nn = tf.keras.models.Sequential()\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "hidden_nodes_layer1 = len(X_train_scaled[0])*4\n",
    "hidden_nodes_layer2 = len(X_train_scaled[0])\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "# DOUBLE AGAIN the number of epochs\n",
    "fit_model = nn.fit(X_train_scaled, numpy.array(y_train), epochs=200)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, numpy.array(y_test),verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy is NOT going in the right direction, 56%!! :/\n",
    "\n",
    "8573/1 - 0s - loss: 0.7088 - accuracy: 0.5598\n",
    "\n",
    "Loss: 0.7132977329835054, Accuracy: 0.5597807168960571"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
